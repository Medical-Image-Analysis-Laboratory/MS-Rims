## Running the docker ##
You need to mount the data (patches) with a csv file referred them with relative paths (check data folder for an example). The models must be mounted as well (TODO host the models somewhere)  
```docker run -v /home/petermcgor/Documents/Projects/rehab_RIMNET/MS-Rims/data:/data -v /home/petermcgor/Documents/Projects/rehab_RIMNET/MS-Rims/models:/models  --gpus device=0  petermcgor/rimnet:0.0.1 dataset_test.csv --model  bimodal_t2star_flair```

# RimNet: A deep 3D multimodal MRI architecture for paramagnetic rim lesions assessment in multiple sclerosis

## How to use?
**IMPORTANT:** all the names of variables used below are inside the file *config.py* unless otherwise specified.

**IMPORTANT 2:** information related to training variables and strategies is stored in [RimNet_Versions](https://docs.google.com/spreadsheets/d/1wla6plWgkqoBFNIsHqFssysvDSYBpeGDz9kHYra-njs/edit?usp=sharing).

### Installation
1. Go to *config.py* and update:
    - PATH_DATA: path to the folder that contains Basel and CHUV (and NIH) datasets.
    - MODELS_LOAD_FROM: path where checkpoints for trained models are saved.
    - MODELS_FIGS_SAVE_TO: path where figures generated in the analysis notebook will be saved.
2. Update variables AVAILABLE_DATASETS and AVAILABLE_DATASETS_ROOTS with the datasets included (remove NIH if not used).

### Pre-processing and patch generation

#### V1 - From segmentations
In folder */scripts/preprocessing/*, execute:

1. Extraction of patches of size PATCH_SIZE using the segmentations (derivatives/rim_annotations). They are saved in the derivatives folder *lesions_XX_XX_XX* where XX is the PATCH_SIZE.

    ```
    python extract_lesions.py
    ```

2. Extraction of bigger patches of size PATCH_SIZE_DEFORMATIONS using the segmentations (derivatives/rim_annotations). They are saved in the derivatives folder *lesions_XX_XX_XX* where XX is the PATCH_SIZE_DEFORMATIONS.

    ```
    python generate_deformations_1.py
    ```

3. Deformation of patches extracted in step 2, application of an elastic deformation with the seed passed as argument and its cropping to size of PATCH_SIZE. They are saved in the derivatives folder *lesions_XX_XX_XX_DEF-Y* where XX is the PATCH_SIZE and Y is the seed.

    ```
    python generate_deformations_2.py 1
    python generate_deformations_2.py 2
    python generate_deformations_2.py 3
    ```

4. Checks lesions that need to be cleaned according to the exclusion criterias explained in the paper (NeuroImage: Clinical), including: lesion too small, too big, rim intrusion and air artifact. Lesions too small are the only ones excluded in both training and testing. The others are only excluded for training. The json files inside each patient's *lesions_XX_XX_XX* will be updated with the exclusion flag and the criteria used for its exclusion.

    ```
    python apply_cleaner.py
    ```

#### V2 - Autosplitting of lesions

No pre-processing is needed. The training/testing scripts will work with the json files generated by */utilities/split_lesions_morphology.ipynb* or */utilities/split_lesions_with_pmaps.ipynb*. Those json files consists of the centers and the rim+/- ground truth of all the lesions, previously retrieved.


### Training
Execute */scripts/train/train.py* for V1 and */scripts/train/train_autosplit.py* for V2. In both modes, you need to specify the following variables: NETWORK_CONTRASTS, NETWORK (architecture, which has to be consistent with the number of contrasts fed as input), LESIONS (if you want to use deformed versions, specify their seeds), NETWORK_NAME (name of the folder that will be created to store checkpoints), DA_ONLINE_STRATEGY (see [RimNet_Versions](https://docs.google.com/spreadsheets/d/1wla6plWgkqoBFNIsHqFssysvDSYBpeGDz9kHYra-njs/edit?usp=sharing)), FOLDS_VERSION (data to use in the training, see *get_folds_structure* function in *utils.py*) and NORMALIZATION_TYPE (see [RimNet_Versions](https://docs.google.com/spreadsheets/d/1wla6plWgkqoBFNIsHqFssysvDSYBpeGDz9kHYra-njs/edit?usp=sharing)). For V2, the SPLIT_VERSION has to be specified.

```
python /scripts/train/train.py #NUM_FOLD_TO_TRAIN
```

### Testing
For V1, execute */scripts/test/test.py* and, for V2, execute */scripts/test/test_segm.py*. Please, mind the SPLIT_VERSION variable for the latter.

- network_name: the same it was specified during the training.
- network: network used for training.
- folds_version: folds to use for testing. Can be different from the training, depending on what is the goal of the testing (could test over the training set, for example, or over unseen data).
- ensemble: if probabilities should be averaged across different fold models.

This script will generate a *csv* file with all the results, that can be analyzed in the */testing/analysis.ipynb* notebook.

**IMPORTANT**: the name of the *csv* file is important to know where it comes from. *NameOfTheModel-TestingFold-ENS.csv*, where ENS appears if the predictions of the several models were averaged working as an ensemble of classifiers.

## How to add new sequences

1. Add it to the dataset folder, as raw or derivative.
2. Add it to *config.py* file, in variable CONTRASTS, with the corresponding attributes.
3. If you want to use it as an input for the network, add the key in PURE_CONTRASTS (inside the if not WORKING_MODE_SKULL_STRIPPED clause).
4. If working with mode V1, re-run the installation to extract the patches from the new sequence.


## How to add new patients

Just add them in the corresponding dataset and modify the folds (see *get_folds_structure* function in *utils.py*) to include them in the training/testing.

## How to add new datasets

Add them in AVAILABLE_DATASETS and AVAILABLE_DATASETS_ROOTS in *config.py*.

---

## Dataset - Derivatives available

- **expert_annotations**: rim+ slices or volumes manually annotated by P.M. or M.A.
- **freesurfer_segmentation**: freesurfer segmentation of the patient, and the version with simplified labels for our project.
- **registrations_to_T2star**: FLAIR, MP(2)RAGE images registered to T2* space. 
- **rim_annotations**: segmentations manually corrected to split rim+ lesions labelled as rim+ (1XXX) or rim- (2XXX).
- **segmentation_probability_maps**: probability maps of the segmentation.
- **segmentation**: segmentation_probability_maps after applying a threshold (0.3).
- **synthetic_mp2rage**: residual data that stayed after trying synthetic MP2RAGE with RimNet.

---

## Code structure

- **root**:
    - config.py: main file, where all the variables used in the project are loaded.
    - deformations.py: functions used to deform the patches generated as offline data augmentation.
    - location.py: functions used to extract the location of the lesions, used for the location analysis.
    - splitlesions_loader.py: auxiliar function to load lesions automatically split.
    - testing.py: functions related to the testing/inference phase.
    - training.py: functions related to the training phase.
    - utils.py and utils_basic.py: functions used all over the project. Functions that load the lesions or their metadata can be found here. Also the function that generates the folds is stored here (needed to change the fold structures).
    - widgets.py: functions to visualize lesions along the 3 dimensions (only working in jupyter-notebook, not in jupyter-lab).
- **archs**: several CNNs architectures used for this project.
- **data_analysis**: notebooks used for lesions analysis (volume, confluent, etc)
- **folds_generation**: genetic algorithm used for the automatic generation of fully balanced (rim+/- and by center) folds.
- **scripts**: scripts for pre-processing, training and testing, useful for the translation to a cluster.
- **testing**: notebooks to evaluate the performance of each model, and correlate it to the decisions of the experts.
- **utilities**: other notebooks used, including registration, link of GT with segmentation, automated splitting of lesions, etc.

---

## Architectures
Only the architectures used most are specified here:
- **monomodal**: the straight-forward simple monomodal CNN.
- **rimnet_bi**: RimNet with 2 inputs, as described in the NeuroImageClinical paper.
- **rimnet**: RimNet with 3 inputs, as described in the MIDL paper.
- **rimnet_bi_plus**: like rimnet_bi with increased complexity in the dense layers. Used to check if the problem with the auto-splitting was given by the number of parameters of the network, which was not.
