{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration...\n",
      "Configuration loaded successfully!\n",
      "_____________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from nibabel import load as load_nii\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.morphology import generate_binary_structure as gbs\n",
    "from scipy.ndimage.measurements import label\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from config import *\n",
    "from utils import generate_BIDS_path, get_dataframe_from_metadata, normalize_patch, load_lesions\n",
    "\n",
    "from confluent_split import load_patient_split_lesions\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"annotated_7T_rimpos\"\n",
    "MIN_VOLUME = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_for_lesions(dataset_id, pat, der_folder, pipeline, session=1):\n",
    "    # we create folder if it does not exist\n",
    "    der_path = os.path.join(AVAILABLE_DATASETS_ROOTS[dataset_id], \"derivatives\", der_folder)\n",
    "    if not os.path.exists(der_path):\n",
    "        try:\n",
    "            os.makedirs(der_path)\n",
    "            print(f\"[INFO] Derivatives folder for '{der_folder}' successfully created.\")\n",
    "        except: # Sometimes in multiprocessing this check is true for several processes and crashes\n",
    "            pass\n",
    "        \n",
    "    # we create the description of the derivatives if it does not exist\n",
    "    dataset_description_path = os.path.join(der_path, \"dataset_description.json\")\n",
    "    if not os.path.exists(os.path.join(dataset_description_path)):\n",
    "        descriptor = {\n",
    "            \"Name\": der_folder,\n",
    "            \"BIDSVersion\": BIDS_VERSION,\n",
    "            \"PipelineDescription\": {\n",
    "                \"Name\": pipeline,\n",
    "                \"version\": VERSION,\n",
    "            }\n",
    "        }\n",
    "        with open(dataset_description_path, \"w\") as outfile:\n",
    "            json.dump(descriptor, outfile)\n",
    "        print(f\"[INFO] Description file for '{der_folder}' successfully created.\")\n",
    "    \n",
    "    # we create the path for the generated file\n",
    "    folder = os.path.join(der_path, f\"sub-{pat:03d}\", f\"ses-{session:02d}\")\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    return folder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_lesions_with_GT(dataset_id, pat, replace=False):\n",
    "    folder_name, pipeline = SPLIT_LESIONS_METADATA[VERSION][\"folder_name\"], SPLIT_LESIONS_METADATA[VERSION][\"pipeline\"]\n",
    "    where_to_save = create_folder_for_lesions(dataset_id, pat, folder_name, pipeline)\n",
    "    \n",
    "    # Loading of paths.\n",
    "    dataset = AVAILABLE_DATASETS[dataset_id]\n",
    "    rimpos_annotations_paths = dataset.get(return_type=\"filename\", subject=f\"{pat:03d}\", **CONTRASTS[\"EXPERTS_ANNOTATIONS\"])\n",
    "    segmentations_paths = dataset.get(return_type=\"filename\", subject=f\"{pat:03d}\", **CONTRASTS[\"SEGMENTATION\"])\n",
    "    meta_lesions_path = generate_BIDS_path(dataset_id, subject=f\"{pat:03d}\", scope=SPLIT_LESIONS_METADATA[VERSION][\"pipeline\"], suffix=SPLIT_LESIONS_METADATA[VERSION][\"suffix\"], acquisition=None, extension=\"csv\")\n",
    "    \n",
    "    if os.path.exists(meta_lesions_path) and not replace:\n",
    "        print(f\"Patient {dataset_id}.{pat} skipped because metadata of split lesions for version {VERSION} already exists.\")\n",
    "        return\n",
    "    \n",
    "    if len(rimpos_annotations_paths) > 0:\n",
    "        gt_lesions = nib.load(rimpos_annotations_paths[0]).get_fdata()\n",
    "    else:\n",
    "        print(f\"[{dataset_id}-{pat}] Experts annotations not available.\")\n",
    "        return\n",
    "    \n",
    "    if len(segmentations_paths) > 0:\n",
    "        seg_lesions = nib.load(segmentations_paths[0]).get_fdata()\n",
    "    else:\n",
    "        print(f\"[{dataset_id}-{pat}] Segmentation not available.\")\n",
    "        return\n",
    "    \n",
    "    # where we will append all lesions\n",
    "    result_data = []\n",
    "    \n",
    "    # RIM+ matching\n",
    "    rimpos_centers = []\n",
    "\n",
    "    labels, num_labels = ndimage.measurements.label(gt_lesions, structure = gbs(3,2))\n",
    "    labels_GT = np.unique(labels)[1:]\n",
    "\n",
    "    for lab in labels_GT:\n",
    "        c = [int(el) for el in ndimage.measurements.center_of_mass(labels == lab)]\n",
    "        vol = np.sum(labels == lab)\n",
    "        result_data.append((dataset_id, pat, 1000 + lab, c[0], c[1], c[2], 100, vol, True))\n",
    "\n",
    "    \n",
    "    # RIM- matching\n",
    "    labels, num_labels = ndimage.measurements.label(seg_lesions)\n",
    "    labels_seg = np.unique(labels)[1:]\n",
    "    \n",
    "    counter = 0\n",
    "    for lab in labels_seg:\n",
    "        lesion_mask = labels == lab\n",
    "        gt_match = (lesion_mask * gt_lesions != 0).any()\n",
    "        if gt_match:\n",
    "            continue # we already included it as Rim+\n",
    "        # FILTER BY VOLUME??\n",
    "        vol = np.sum(lesion_mask)\n",
    "        if vol >= MIN_VOLUME:\n",
    "            c = [int(el) for el in ndimage.measurements.center_of_mass(lesion_mask)]\n",
    "            result_data.append((dataset_id, pat, 2000 + counter, c[0], c[1], c[2], \"\", \"\", True))\n",
    "            counter += 1\n",
    "    \n",
    "    # *real* column is meant for those cases where data augmentation is applied in this phase => \"False\" to avoid using them in testing\n",
    "    df = pd.DataFrame(result_data, columns=[\"dataset_id\", \"patient\", \"lesion\", \"x\", \"y\", \"z\", \"percentage_rims\", \"voxels_rims\", \"real\"])\n",
    "    df.to_csv(meta_lesions_path, index=False)\n",
    "    print(f'{dataset_id}- Pat {pat:02d}: {len(df[df[\"lesion\"] // 1000 == 1].index)}/{len(df[df[\"lesion\"] // 2000 == 1].index)}')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2- Pat 20: 7/18\n"
     ]
    }
   ],
   "source": [
    "# RUN\n",
    "for pat in tqdm(DATASET_NIH7T.get_subjects()):\n",
    "    df = match_lesions_with_GT(DATASET_NIH7T_ID, int(pat), replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_patients_metadata():\n",
    "    to_concat = []\n",
    "    for dataset_id in range(len(AVAILABLE_DATASETS)):\n",
    "        dataset = AVAILABLE_DATASETS[dataset_id]\n",
    "        for pat in dataset.get_subjects():\n",
    "            paths = dataset.get(return_type=\"filename\", subject=f\"{pat}\", scope=SPLIT_LESIONS_METADATA[VERSION][\"pipeline\"], suffix=SPLIT_LESIONS_METADATA[VERSION][\"suffix\"], acquisition=None, extension=\"csv\")\n",
    "            if len(paths) == 1:\n",
    "                to_concat.append(pd.read_csv(paths[0]))\n",
    "                #pd.read_csv(paths[0])[[\"dataset_id\", \"patient\", \"lesion\", \"x\", \"y\", \"z\", \"percentage_rims\", \"voxels_rims\", \"real\"]].to_csv(paths[0], index=False)\n",
    "\n",
    "    df = pd.concat(to_concat)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_all_patients_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - 1\n",
      "2 - 3\n",
      "3 - 22\n",
      "4 - 6\n",
      "5 - 11\n",
      "6 - 12\n",
      "7 - 4\n",
      "8 - 5\n",
      "9 - 5\n",
      "10 - 1\n",
      "11 - 4\n",
      "12 - 9\n",
      "13 - 27\n",
      "14 - 41\n",
      "15 - 21\n",
      "16 - 3\n",
      "17 - 8\n",
      "18 - 18\n",
      "19 - 4\n",
      "20 - 7\n"
     ]
    }
   ],
   "source": [
    "for pat, grouped in df.groupby(\"patient\"):\n",
    "    print(f\"{pat} - {len(grouped.index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding of PMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating segmentation for patient 010...\n"
     ]
    }
   ],
   "source": [
    "TH = 0.3\n",
    "\n",
    "dataset = DATASET_NIH7T\n",
    "for patient in (\"010\", ):#dataset.get_subjects():\n",
    "    print(f\"Generating segmentation for patient {patient}...\")\n",
    "    pmap_path = dataset.get(return_type=\"filename\", subject=f\"{patient}\", **CONTRASTS[\"PMAP\"])\n",
    "    if len(pmap_path) == 0:\n",
    "        print(f\"PROBLEM: {patient}\")\n",
    "        continue\n",
    "    pmap_path = pmap_path[0]\n",
    "    \n",
    "    im = nib.load(pmap_path)\n",
    "    image = im.get_fdata()\n",
    "    \n",
    "    thresholded = np.zeros_like(image)\n",
    "    thresholded[image >= TH] = 1\n",
    "    \n",
    "    new_image = nib.Nifti1Image(thresholded, im.affine, im.header)\n",
    "    \n",
    "    segmentation_path = generate_BIDS_path(DATASET_NIH7T_ID, subject=patient, **CONTRASTS[\"SEGMENTATION\"])\n",
    "    nib.save(new_image, segmentation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
